{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0cb2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_palette('muted')\n",
    "sns.set_color_codes('muted')\n",
    "sns.set_style('white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b99e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931fe73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8150a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>User estimate</th>\n",
       "      <th>Users qty</th>\n",
       "      <th>Critics estimate</th>\n",
       "      <th>Critic qty</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>41.36</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Sport games</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>28.96</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Sport games</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>JP_Sales</td>\n",
       "      <td>3.77</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Sport games</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Other_Sales</td>\n",
       "      <td>8.45</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Sport games</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>29.08</td>\n",
       "      <td>NES</td>\n",
       "      <td>Platformers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Game name  Year of release       Region  Sales Platform  \\\n",
       "0         Wii Sports           2006.0     NA_Sales  41.36      Wii   \n",
       "1         Wii Sports           2006.0     EU_Sales  28.96      Wii   \n",
       "2         Wii Sports           2006.0     JP_Sales   3.77      Wii   \n",
       "3         Wii Sports           2006.0  Other_Sales   8.45      Wii   \n",
       "4  Super Mario Bros.           1985.0     NA_Sales  29.08      NES   \n",
       "\n",
       "         Genre Developer Publisher User estimate  Users qty  Critics estimate  \\\n",
       "0  Sport games  Nintendo  Nintendo             8      322.0              76.0   \n",
       "1  Sport games  Nintendo  Nintendo             8      322.0              76.0   \n",
       "2  Sport games  Nintendo  Nintendo             8      322.0              76.0   \n",
       "3  Sport games  Nintendo  Nintendo             8      322.0              76.0   \n",
       "4  Platformers       NaN  Nintendo           NaN        NaN               NaN   \n",
       "\n",
       "   Critic qty Rating  \n",
       "0        51.0      E  \n",
       "1        51.0      E  \n",
       "2        51.0      E  \n",
       "3        51.0      E  \n",
       "4         NaN    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VideoGames = pd.read_excel('VideoGames.xlsx')\n",
    "\n",
    "VideoGames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987fd48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66876 entries, 0 to 66875\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Game name         66868 non-null  object \n",
      " 1   Year of release   65800 non-null  float64\n",
      " 2   Region            66876 non-null  object \n",
      " 3   Sales             66876 non-null  float64\n",
      " 4   Platform          66876 non-null  object \n",
      " 5   Genre             66868 non-null  object \n",
      " 6   Developer         40384 non-null  object \n",
      " 7   Publisher         66660 non-null  object \n",
      " 8   User estimate     40060 non-null  object \n",
      " 9   Users qty         30360 non-null  float64\n",
      " 10  Critics estimate  32548 non-null  float64\n",
      " 11  Critic qty        32548 non-null  float64\n",
      " 12  Rating            39800 non-null  object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "VideoGames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155e9a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoGames = VideoGames.loc[VideoGames['Year of release'].isin([2010, 2011, 2012, 2013, 2014, 2015, 2016])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1929c718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>User estimate</th>\n",
       "      <th>Users qty</th>\n",
       "      <th>Critics estimate</th>\n",
       "      <th>Critic qty</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>15.00</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>6.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>4.89</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>6.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>JP_Sales</td>\n",
       "      <td>0.24</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>6.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Other_Sales</td>\n",
       "      <td>1.69</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>6.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>7.02</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Game name  Year of release       Region  Sales Platform   Genre  \\\n",
       "56  Kinect Adventures!           2010.0     NA_Sales  15.00     X360   Other   \n",
       "57  Kinect Adventures!           2010.0     EU_Sales   4.89     X360   Other   \n",
       "58  Kinect Adventures!           2010.0     JP_Sales   0.24     X360   Other   \n",
       "59  Kinect Adventures!           2010.0  Other_Sales   1.69     X360   Other   \n",
       "64  Grand Theft Auto V           2013.0     NA_Sales   7.02      PS3  Action   \n",
       "\n",
       "              Developer               Publisher User estimate  Users qty  \\\n",
       "56  Good Science Studio  Microsoft Game Studios           6.3      106.0   \n",
       "57  Good Science Studio  Microsoft Game Studios           6.3      106.0   \n",
       "58  Good Science Studio  Microsoft Game Studios           6.3      106.0   \n",
       "59  Good Science Studio  Microsoft Game Studios           6.3      106.0   \n",
       "64       Rockstar North    Take-Two Interactive           8.2     3994.0   \n",
       "\n",
       "    Critics estimate  Critic qty Rating  \n",
       "56              61.0        45.0      E  \n",
       "57              61.0        45.0      E  \n",
       "58              61.0        45.0      E  \n",
       "59              61.0        45.0      E  \n",
       "64              97.0        50.0      M  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VideoGames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40972b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoGames = VideoGames.drop(['User estimate', 'Users qty', 'Critics estimate', 'Critic qty'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c18e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the dataset by game name and sum the sales\n",
    "game_sales = VideoGames.groupby('Game name')['Sales'].sum()\n",
    "\n",
    "#Reset the index\n",
    "game_sales = game_sales.reset_index()\n",
    "\n",
    "#Merge the game_sales dataframe with the original dataset on game name\n",
    "VideoGames = pd.merge(VideoGames, game_sales, on='Game name')\n",
    "\n",
    "#Rename the Sales column to Total Sales\n",
    "VideoGames = VideoGames.rename(columns={'Sales_y': 'Total Sales'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9b3972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game name</th>\n",
       "      <th>Year of release</th>\n",
       "      <th>Region</th>\n",
       "      <th>Sales_x</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>15.00</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>E</td>\n",
       "      <td>21.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>4.89</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>E</td>\n",
       "      <td>21.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>JP_Sales</td>\n",
       "      <td>0.24</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>E</td>\n",
       "      <td>21.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kinect Adventures!</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Other_Sales</td>\n",
       "      <td>1.69</td>\n",
       "      <td>X360</td>\n",
       "      <td>Other</td>\n",
       "      <td>Good Science Studio</td>\n",
       "      <td>Microsoft Game Studios</td>\n",
       "      <td>E</td>\n",
       "      <td>21.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>7.02</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>9.09</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>JP_Sales</td>\n",
       "      <td>0.98</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Other_Sales</td>\n",
       "      <td>3.96</td>\n",
       "      <td>PS3</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NA_Sales</td>\n",
       "      <td>9.66</td>\n",
       "      <td>X360</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Grand Theft Auto V</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>EU_Sales</td>\n",
       "      <td>5.14</td>\n",
       "      <td>X360</td>\n",
       "      <td>Action</td>\n",
       "      <td>Rockstar North</td>\n",
       "      <td>Take-Two Interactive</td>\n",
       "      <td>M</td>\n",
       "      <td>56.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Game name  Year of release       Region  Sales_x Platform   Genre  \\\n",
       "0  Kinect Adventures!           2010.0     NA_Sales    15.00     X360   Other   \n",
       "1  Kinect Adventures!           2010.0     EU_Sales     4.89     X360   Other   \n",
       "2  Kinect Adventures!           2010.0     JP_Sales     0.24     X360   Other   \n",
       "3  Kinect Adventures!           2010.0  Other_Sales     1.69     X360   Other   \n",
       "4  Grand Theft Auto V           2013.0     NA_Sales     7.02      PS3  Action   \n",
       "5  Grand Theft Auto V           2013.0     EU_Sales     9.09      PS3  Action   \n",
       "6  Grand Theft Auto V           2013.0     JP_Sales     0.98      PS3  Action   \n",
       "7  Grand Theft Auto V           2013.0  Other_Sales     3.96      PS3  Action   \n",
       "8  Grand Theft Auto V           2013.0     NA_Sales     9.66     X360  Action   \n",
       "9  Grand Theft Auto V           2013.0     EU_Sales     5.14     X360  Action   \n",
       "\n",
       "             Developer               Publisher Rating  Total Sales  \n",
       "0  Good Science Studio  Microsoft Game Studios      E        21.82  \n",
       "1  Good Science Studio  Microsoft Game Studios      E        21.82  \n",
       "2  Good Science Studio  Microsoft Game Studios      E        21.82  \n",
       "3  Good Science Studio  Microsoft Game Studios      E        21.82  \n",
       "4       Rockstar North    Take-Two Interactive      M        56.58  \n",
       "5       Rockstar North    Take-Two Interactive      M        56.58  \n",
       "6       Rockstar North    Take-Two Interactive      M        56.58  \n",
       "7       Rockstar North    Take-Two Interactive      M        56.58  \n",
       "8       Rockstar North    Take-Two Interactive      M        56.58  \n",
       "9       Rockstar North    Take-Two Interactive      M        56.58  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VideoGames.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c51107dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoGames.to_excel('VideoGamesaltered.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70129acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset='OriginalTweet').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.TweetAt = pd.to_datetime(train.TweetAt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.TweetAt.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66b6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_per_day\n",
    "tweets_per_day = train[['TweetAt']].set_index(train['TweetAt']).resample('D').count()\n",
    "tweets_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6796656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_per_day_simple  strftime\n",
    "tweets_per_day_simple = train.TweetAt.dt.strftime('%m-%d').value_counts().sort_index()\n",
    "tweets_per_day_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d0c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_locations1 = ['California, USA', 'Chicago, IL', 'San Francisco, CA', 'USA', 'Los Angeles, CA', 'Washington, DC', 'New York, NY']\n",
    "train['Location'].replace(merge_locations1, 'United States', inplace=True)\n",
    "\n",
    "merge_locations2 = ['England, United Kingdom', 'UK', 'London, England', 'London']\n",
    "train['Location'].replace(merge_locations2, 'United Kingdom', inplace=True)\n",
    "\n",
    "merge_locations3 = ['Toronto, Ontario']\n",
    "train['Location'].replace(merge_locations3, 'Canada', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc2a3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_by_country  = train.Location.value_counts()\n",
    "tweets_by_country_freq = tweets_by_country[tweets_by_country > 100]\n",
    "tweets_by_country_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3adfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_country_freq.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['Location','Sentiment']).size().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_country_sentiment = train.groupby(['Location','Sentiment']).size().reset_index()\n",
    "tweets_by_country_sentiment.columns = ['Location', 'Sentiment', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.TweetAt.dt.month\n",
    "train['day'] = train.TweetAt.dt.day\n",
    "train['dayofweek'] = train.TweetAt.dt.dayofweek\n",
    "train['weekday'] = train.TweetAt.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dayofweek.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweetlength'] = train.OriginalTweet.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d832aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['OriginalTweet'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20482fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_usernames_links(tweet):\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub('http[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r'[^a-zA-Z\\s]', '', tweet)\n",
    "    tweet = ' '.join(tweet.split())\n",
    "    return tweet\n",
    "\n",
    "train['CleanTweet'] = train['OriginalTweet'].apply(remove_usernames_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ca966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['CleanTweet'] = train['CleanTweet'].apply(lambda x: x.replace('\\n', ' '))\n",
    "train['CleanTweet'] = train['CleanTweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "train['CleanTweet'] = train['CleanTweet'].apply(lambda x: cleaning_repeating_char(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['CleanTweet'][26968]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523beec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CleanTweet[1].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a987dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f724d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebcd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # Split the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Lemmatize each word and join them back into a string\n",
    "    return ' '.join([wnl.lemmatize(word, get_wordnet_pos(word)) for word in words])\n",
    "\n",
    "# Apply the lemmatization function to the text data\n",
    "train['CleanTweet'] = train['CleanTweet'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CleanTweet[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f382552",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(train[['CleanTweet']], \n",
    "                                                                        train.Sentiment,\n",
    "                                                                        stratify=train.Sentiment,\n",
    "                                                                        test_size = 0.25,\n",
    "                                                                        random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6adafc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10563e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()\n",
    "pipeline_dr = Pipeline(steps = [('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                                            max_df=.85,\n",
    "                                                            min_df=.0001,\n",
    "                                                            stop_words = 'english'\n",
    "                                                            )\n",
    "                                ), \n",
    "                                ('to_dense', DenseTransformer()),\n",
    "                                ('pca', PCA(n_components=2000)), \n",
    "                                ('classifier', GaussianProcessClassifier())\n",
    "                            ])\n",
    "\n",
    "%time pipeline_dr.fit(X_train_text.CleanTweet, y_train_text)\n",
    "\n",
    "pipeline_dr_pred_train = pipeline_dr.predict(X_train_text.CleanTweet)\n",
    "pipeline_dr_pred_test = pipeline_dr.predict(X_test_text.CleanTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260ef6d",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "        \n",
    "params_grid = dict(min_df=[0.001], max_df=[0.9])\n",
    "\n",
    "resultsdtc = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('tf_idf_vec', TfidfVectorizer(\n",
    "            token_pattern=r'[A-Za-z]{2,}',\n",
    "            max_df=params['max_df'],\n",
    "            min_df=params['min_df'],\n",
    "            stop_words='english'\n",
    "        )), \n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "    \n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "    \n",
    "    resultsdtc.append(dict(\n",
    "        params=params,\n",
    "        \n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),       \n",
    "        \n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "        \n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "    \n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dadb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdtc = pd.DataFrame(resultsdtc)\n",
    "resultsdtc.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worse with grid search than on default\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "        \n",
    "params_grid = dict(min_df=[0.001], max_df=[0.9], max_depth=[4, 6, 8], min_samples_split=[2, 5, 10], min_samples_leaf=[1, 2, 4])\n",
    "\n",
    "resultsdtc = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('tf_idf_vec', TfidfVectorizer(\n",
    "            token_pattern=r'[A-Za-z]{2,}',\n",
    "            max_df=params['max_df'],\n",
    "            min_df=params['min_df'],\n",
    "            stop_words='english'\n",
    "        )), \n",
    "        ('classifier', DecisionTreeClassifier(\n",
    "            max_depth=params['max_depth'],\n",
    "            min_samples_split=params['min_samples_split'],\n",
    "            min_samples_leaf=params['min_samples_leaf'],\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "    \n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "    \n",
    "    resultsdtc.append(dict(\n",
    "        params=params,\n",
    "        \n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),       \n",
    "        \n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "        \n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "    \n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsdtc = pd.DataFrame(resultsdtc)\n",
    "resultsdtc.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c35d8b7",
   "metadata": {},
   "source": [
    "## Params for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the pipe for finding best params for vectorizer first for svc\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "params_grid = dict(min_df=[.0001, .0005, .0007, .001, .005, .01], max_df=[.7, .75, .8, .85, .9])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                            max_df=params['max_df'],\n",
    "                            min_df=params['min_df'],\n",
    "                            stop_words='english')\n",
    "    \n",
    "    tfidf.fit(X_train_text['CleanTweet'])\n",
    "    X_train_tfidf = tfidf.transform(X_train_text['CleanTweet'])\n",
    "    X_test_tfidf = tfidf.transform(X_test_text['CleanTweet'])\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train_tfidf, y_train_text)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_score(y_test_text, y_pred)\n",
    "    \n",
    "    results.append(dict(\n",
    "        params=params,\n",
    "        accuracy=acc\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by='accuracy', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85391cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# encode target variable\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train_text)\n",
    "y_test_enc = le.transform(y_test_text)\n",
    "\n",
    "params_grid = dict(min_df=[.0001, .0005, .0007, .001, .005, .01], max_df=[.7, .75, .8, .85, .9])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                            max_df=params['max_df'],\n",
    "                            min_df=params['min_df'],\n",
    "                            stop_words='english')\n",
    "    \n",
    "    tfidf.fit(X_train_text['CleanTweet'])\n",
    "    X_train_tfidf = tfidf.transform(X_train_text['CleanTweet'])\n",
    "    X_test_tfidf = tfidf.transform(X_test_text['CleanTweet'])\n",
    "    \n",
    "    etc = XGBClassifier()\n",
    "    etc.fit(X_train_tfidf, y_train_enc)\n",
    "    y_pred_enc = etc.predict(X_test_tfidf)\n",
    "    y_pred = le.inverse_transform(y_pred_enc)\n",
    "    \n",
    "    acc = accuracy_score(y_test_text, y_pred)\n",
    "    \n",
    "    results.append(dict(\n",
    "        params=params,\n",
    "        accuracy=acc\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by='accuracy', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params_grid = dict(min_df=[.0001, .0005, .0007, .001, .005, .01], max_df=[.7, .75, .8, .85, .9])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                            max_df=params['max_df'],\n",
    "                            min_df=params['min_df'],\n",
    "                            stop_words='english')\n",
    "    \n",
    "    tfidf.fit(X_train_text['CleanTweet'])\n",
    "    X_train_tfidf = tfidf.transform(X_train_text['CleanTweet'])\n",
    "    X_test_tfidf = tfidf.transform(X_test_text['CleanTweet'])\n",
    "    \n",
    "    clf = ExtraTreesClassifier()\n",
    "    clf.fit(X_train_tfidf, y_train_text)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_score(y_test_text, y_pred)\n",
    "    \n",
    "    results.append(dict(\n",
    "        params=params,\n",
    "        accuracy=acc\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by='accuracy', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f91aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "params_grid = dict(min_df=[.0001, .0005, .0007, .001, .005, .01], max_df=[.7, .75, .8, .85, .9])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    tfidf = TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                            max_df=params['max_df'],\n",
    "                            min_df=params['min_df'],\n",
    "                            stop_words='english')\n",
    "    \n",
    "    tfidf.fit(X_train_text['CleanTweet'])\n",
    "    X_train_tfidf = tfidf.transform(X_train_text['CleanTweet'])\n",
    "    X_test_tfidf = tfidf.transform(X_test_text['CleanTweet'])\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_tfidf, y_train_text)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    acc = accuracy_score(y_test_text, y_pred)\n",
    "    \n",
    "    results.append(dict(\n",
    "        params=params,\n",
    "        accuracy=acc\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by='accuracy', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa9238",
   "metadata": {},
   "source": [
    "### The best params for TF-IDF will be\n",
    "#### LinearSVC: 'max_df': 0.85, 'min_df': 0.0005 \n",
    "#### CatBoost: takes too long\n",
    "#### XGBoost: 'max_df': 0.8, 'min_df': 0.0005\n",
    "#### MultinomialNB: 'max_df': 0.8, 'min_df': 0.001\n",
    "#### GPC: requires numpy array\n",
    "#### ExtraTreesClassifier: 'max_df': 0.85, 'min_df': 0.0007"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c553f9",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00999e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a9e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "params_grid = dict(min_df=[.0005], max_df=[0.85])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps = [('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                                            max_df=params['max_df'],\n",
    "                                                            min_df=params['min_df'],\n",
    "                                                            stop_words = 'english'\n",
    "                                                            ))\n",
    "                            ])\n",
    "\n",
    "    # Define the parameter grid for the CatBoostClassifier\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 500, 1000],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1]\n",
    "    }\n",
    "\n",
    "    # Add the CatBoostClassifier to the pipeline\n",
    "    pipe.steps.append(['classifier', CatBoostClassifier()])\n",
    "\n",
    "    # Perform the grid search\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=5, verbose=1, scoring='accuracy')\n",
    "    grid_search.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "\n",
    "    # Print the best parameters\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b19ae3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# encode target variable\n",
    "le = LabelEncoder()\n",
    "y_train_text_enc = le.fit_transform(y_train_text)\n",
    "y_test_text_enc = le.transform(y_test_text)\n",
    "\n",
    "params_grid = dict(min_df=[0.0005], max_df=[0.8], learning_rate=[0.01], max_depth=[9], \n",
    "                   subsample=[1.0], n_estimators=[400])\n",
    "\n",
    "resultsxgb = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps = [\n",
    "        ('tf_idf_vec', TfidfVectorizer(\n",
    "            token_pattern=r'[A-Za-z]{2,}',\n",
    "            max_df=params['max_df'],\n",
    "            min_df=params['min_df'],\n",
    "            stop_words='english'\n",
    "        )), \n",
    "        ('classifier', XGBClassifier(\n",
    "            learning_rate=params['learning_rate'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            subsample=params['subsample'],\n",
    "            verbosity=0\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text_enc)\n",
    "    \n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "    \n",
    "    # decode predicted labels\n",
    "    pipe_preds_train_dec = le.inverse_transform(pipe_preds_train)\n",
    "    pipe_preds_test_dec = le.inverse_transform(pipe_preds_test)\n",
    "    \n",
    "    resultsxgb.append(dict(\n",
    "        params=params,\n",
    "        \n",
    "        precision_train=precision_score(y_true=y_train_text_enc, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text_enc, y_pred=pipe_preds_test, average='macro'),       \n",
    "        \n",
    "        recall_train=recall_score(y_true=y_train_text_enc, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text_enc, y_pred=pipe_preds_test, average='macro'),\n",
    "        \n",
    "        f1_train=f1_score(y_true=y_train_text_enc, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text_enc, y_pred=pipe_preds_test, average='macro'),\n",
    "    \n",
    "        accuracy_train=accuracy_score(y_true=y_train_text_enc, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text_enc, y_pred=pipe_preds_test),\n",
    "        \n",
    "        # add decoded predicted labels\n",
    "        preds_train_dec=pipe_preds_train_dec,\n",
    "        preds_test_dec=pipe_preds_test_dec\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsxgb = pd.DataFrame(resultsxgb)\n",
    "resultsxgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fccb4f",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "params_grid = dict(min_df=[0.001], \n",
    "                   max_df=[0.8],\n",
    "                   alpha=[0.1, 0.5, 1, 2, 5],\n",
    "                   )\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps=[('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                                            max_df=params['max_df'],\n",
    "                                                            min_df=params['min_df'],\n",
    "                                                            stop_words='english'\n",
    "                                                            )\n",
    "                            ),\n",
    "                            ('classifier', MultinomialNB(alpha=params['alpha']))\n",
    "                            ])\n",
    "\n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "\n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "\n",
    "    results.append(dict(\n",
    "\n",
    "        params=params,\n",
    "\n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab38899",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0229f",
   "metadata": {},
   "source": [
    "## GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "params_grid = dict(\n",
    "    min_df=[0.0005],\n",
    "    max_df=[0.85],\n",
    "    kernel=[1.0 * RBF(length_scale=1.0), 1.0 * RBF(length_scale=0.5), 1.0 * RBF(length_scale=2.0)],\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                       max_df=params['max_df'],\n",
    "                                       min_df=params['min_df'],\n",
    "                                       stop_words='english')),\n",
    "        ('classifier', GaussianProcessClassifier(kernel=params['kernel']))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "\n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "\n",
    "    results.append(dict(\n",
    "        params=params,\n",
    "\n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3189c9",
   "metadata": {},
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs better on default than on grid search\n",
    "# 54% vs. 28%\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "params_grid = dict(min_df=[0.0007],\n",
    "                   max_df=[0.85],\n",
    "                   max_depth=[6, 7, 8, 9],\n",
    "                   n_estimators=[100, 200, 300],\n",
    "                   min_samples_split=[2, 3, 4])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps=[('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                                          max_df=params['max_df'],\n",
    "                                                          min_df=params['min_df'],\n",
    "                                                          stop_words='english')\n",
    "                            ),\n",
    "                           ('classifier', ExtraTreesClassifier(max_depth=params['max_depth'],\n",
    "                                                                n_estimators=params['n_estimators'],\n",
    "                                                                min_samples_split=params['min_samples_split']))\n",
    "                           ])\n",
    "\n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "\n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "\n",
    "    results.append(dict(\n",
    "\n",
    "        params=params,\n",
    "\n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f01b7",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "params_grid = dict(min_df=[0.0005],\n",
    "                   max_df=[0.85],\n",
    "                   C=[1, 10, 100],\n",
    "                   gamma=[0.1, 0.01, 0.001],\n",
    "                   kernel=['linear', 'rbf'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps=[('tf_idf_vec', TfidfVectorizer(token_pattern=r'[A-Za-z]{2,}',\n",
    "                                                          max_df=params['max_df'],\n",
    "                                                          min_df=params['min_df'],\n",
    "                                                          stop_words='english')\n",
    "                            ),\n",
    "                           ('classifier', SVC(C=params['C'],\n",
    "                                               gamma=params['gamma'],\n",
    "                                               kernel=params['kernel']))\n",
    "                           ])\n",
    "\n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "\n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "\n",
    "    results.append(dict(\n",
    "\n",
    "        params=params,\n",
    "\n",
    "        precision_train=precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test=precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        recall_train=recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test=recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        f1_train=f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test=f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "\n",
    "        accuracy_train=accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test=accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e0592",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2b442",
   "metadata": {},
   "source": [
    "|  Model                |  Default accuracy |  Grid accuracy |\n",
    "|-----------------------|-------------------|----------------|\n",
    "| XGBoost               |  0.522687         |  0.458778      |\n",
    "| SVC                   |  0.537663         |  0.590896      |\n",
    "| DecisionTreeClassifier|  0.414442         |  0.339413      |\n",
    "| ExtraTreesClassifier  |  0.548636         |  0.288998      |\n",
    "| MultinominalNB        |  0.440391         |  0.452254      |\n",
    "| CatBoost              |        -          |       -        |\n",
    "| GaussianPC            |        -          |       -        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed167122",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d84b47",
   "metadata": {},
   "source": [
    "#### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b78ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eed884",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9203f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "import torch \n",
    "\n",
    "def texts_to_embeddings(texts):\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "    input_ids = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(input_ids).last_hidden_state[:, 0, :]\n",
    "    return embeddings.numpy()\n",
    "\n",
    "train_texts = train['CleanTweet'].tolist()  # convert to list of strings\n",
    "train_embeddings = texts_to_embeddings(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b2ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Sentiments']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1948b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a23c2",
   "metadata": {},
   "source": [
    "#### XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38236f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17fb1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import XLNetTokenizer, XLNetModel\n",
    "import torch\n",
    "\n",
    "# Instantiate the XLNet tokenizer and model\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "model = XLNetModel.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "def xlnet_embeddings(text):\n",
    "    # Tokenize the text\n",
    "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
    "    \n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)[0][:, 0, :].numpy()  # Use the first token as the embedding\n",
    "    \n",
    "    return output\n",
    "\n",
    "params_grid = dict(min_df=[.0001, .0005, .0007, .001, .005, .01], max_df=[.7, .75, .8, .85, .9],max_depth=[6,7,8,9])\n",
    "\n",
    "results = []\n",
    "\n",
    "for params in tqdm(ParameterGrid(params_grid)):\n",
    "    pipe = Pipeline(steps = [('embedding', FunctionTransformer(xlnet_embeddings, validate=False)),\n",
    "                              ('classifier',DecisionTreeClassifier(max_depth=params['max_depth']\n",
    "                                                                      ))\n",
    "                            ])\n",
    "    \n",
    "    pipe.fit(X_train_text['CleanTweet'], y_train_text)\n",
    "    \n",
    "    \n",
    "    pipe_preds_train = pipe.predict(X_train_text.CleanTweet)\n",
    "    pipe_preds_test = pipe.predict(X_test_text.CleanTweet)\n",
    "    \n",
    "    results.append(dict(\n",
    "        \n",
    "        params=params,\n",
    "        \n",
    "        precision_train = precision_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        precision_test = precision_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),       \n",
    "        \n",
    "        recall_train = recall_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        recall_test = recall_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "        \n",
    "        f1_train = f1_score(y_true=y_train_text, y_pred=pipe_preds_train, average='macro'),\n",
    "        f1_test = f1_score(y_true=y_test_text, y_pred=pipe_preds_test, average='macro'),\n",
    "    \n",
    "        accuracy_train = accuracy_score(y_true=y_train_text, y_pred=pipe_preds_train),\n",
    "        accuracy_test = accuracy_score(y_true=y_test_text, y_pred=pipe_preds_test)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58d9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values('accuracy_test', ascending=False).head(10).style.bar(vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5af8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf5be1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
